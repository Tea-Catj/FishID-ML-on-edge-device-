{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNfJzxmqfwKJAAz5CFmEZ+N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Xjs4lCphb76q"},"outputs":[],"source":["# Clone the tensorflow models repository from GitHub\n","!pip uninstall Cython -y # Temporary fix for \"No module named 'object_detection'\" error\n","!git clone --depth 1 https://github.com/tensorflow/models"]},{"cell_type":"code","source":["# Copy setup files into models/research folder\n","%%bash\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","#cp object_detection/packages/tf2/setup.py ."],"metadata":{"id":"WlEB7qnicNs9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modify setup.py file to install the tf-models-official repository targeted at TF v2.8.0\n","import re\n","with open('/content/models/research/object_detection/packages/tf2/setup.py') as f:\n","    s = f.read()\n","\n","with open('/content/models/research/setup.py', 'w') as f:\n","    # Set fine_tune_checkpoint path\n","    s = re.sub('tf-models-official>=2.5.1',\n","               'tf-models-official==2.8.0', s)\n","    f.write(s)"],"metadata":{"id":"PN0WWNLHcTC0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OLDnCkLLwLr6"},"outputs":[],"source":["# Install the Object Detection API (NOTE: This block takes about 10 minutes to finish executing)\n","\n","# Need to do a temporary fix with PyYAML because Colab isn't able to install PyYAML v5.4.1\n","!pip install pyyaml==5.3\n","!pip install /content/models/research/\n","\n","# Need to downgrade to TF v2.8.0 due to Colab compatibility bug with TF v2.10 (as of 10/03/22)\n","!pip install tensorflow==2.8.0\n","\n","# Install CUDA version 11.0 (to maintain compatibility with TF v2.8.0)\n","!pip install tensorflow_io==0.23.1\n","!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n","!mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n","!wget http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n","!dpkg -i cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n","!apt-key add /var/cuda-repo-ubuntu1804-11-0-local/7fa2af80.pub\n","!apt-get update && sudo apt-get install cuda-toolkit-11-0\n","!export LD_LIBRARY_PATH=/usr/local/cuda-11.0/lib64:$LD_LIBRARY_PATH"]},{"cell_type":"markdown","source":["error checking"],"metadata":{"id":"7lpEe3HDcf40"}},{"cell_type":"code","source":["# Run Model Bulider Test file, just to verify everything's working properly\n","!python /content/models/research/object_detection/builders/model_builder_tf2_test.py\n"],"metadata":{"id":"n3CR-sY3ce4D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["convert dataset to tf record"],"metadata":{"id":"FBjKu7WncxOc"}},{"cell_type":"code","source":["# Download data conversion scripts\n","! wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/create_csv.py\n","! wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/create_tfrecord.py"],"metadata":{"id":"h0J8tigAcwPD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create CSV data files and TFRecord files\n","!python3 create_csv.py\n","!python3 create_tfrecord.py --csv_input=images/train_labels.csv --labelmap=labelmap.txt --image_dir=images/train --output_path=train.tfrecord\n","!python3 create_tfrecord.py --csv_input=images/validation_labels.csv --labelmap=labelmap.txt --image_dir=images/validation --output_path=val.tfrecord"],"metadata":{"id":"JnNMfagYc7bT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_record_fname = '/content/train.tfrecord'\n","val_record_fname = '/content/val.tfrecord'\n","label_map_pbtxt_fname = '/content/labelmap.pbtxt'"],"metadata":{"id":"S4jaY4oxdBps"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Training setup"],"metadata":{"id":"EaJ8o8p2dJ2t"}},{"cell_type":"code","source":["# Change the chosen_model variable to deploy different models available in the TF2 object detection zoo\n","chosen_model = 'ssd-mobilenet-v2-fpnlite-320'\n","\n","MODELS_CONFIG = {\n","    'ssd-mobilenet-v2': {\n","        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n","        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n","    },\n","    'efficientdet-d0': {\n","        'model_name': 'efficientdet_d0_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n","    },\n","    'ssd-mobilenet-v2-fpnlite-320': {\n","        'model_name': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8',\n","        'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz',\n","    },\n","    # The centernet model isn't working as of 9/10/22\n","    #'centernet-mobilenet-v2': {\n","    #    'model_name': 'centernet_mobilenetv2fpn_512x512_coco17_od',\n","    #    'base_pipeline_file': 'pipeline.config',\n","    #    'pretrained_checkpoint': 'centernet_mobilenetv2fpn_512x512_coco17_od.tar.gz',\n","    #}\n","}\n","\n","model_name = MODELS_CONFIG[chosen_model]['model_name']\n","pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n","base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']"],"metadata":{"id":"-UokRQI1dI5c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create \"mymodel\" folder for holding pre-trained weights and configuration files\n","%mkdir /content/models/mymodel/\n","%cd /content/models/mymodel/\n","\n","# Download pre-trained model weights\n","import tarfile\n","download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n","!wget {download_tar}\n","tar = tarfile.open(pretrained_checkpoint)\n","tar.extractall()\n","tar.close()\n","\n","# Download training configuration file for model\n","download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n","!wget {download_config}"],"metadata":{"id":"64Ze_sOGdU1N"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1lYDvJN-n69v"},"outputs":[],"source":["# Set training parameters for the model\n","num_steps = 40000\n","\n","if chosen_model == 'efficientdet-d0':\n","  batch_size = 4\n","else:\n","  batch_size = 16"]},{"cell_type":"code","source":["# Set file locations and get number of classes for config file\n","pipeline_fname = '/content/models/mymodel/' + base_pipeline_file\n","fine_tune_checkpoint = '/content/models/mymodel/' + model_name + '/checkpoint/ckpt-0'\n","\n","def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","print('Total classes:', num_classes)\n"],"metadata":{"id":"but_sGBneoWM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5eA5ht3_yukT"},"outputs":[],"source":["# Create custom configuration file by writing the dataset, model checkpoint, and training parameters into the base pipeline file\n","import re\n","\n","%cd /content/models/mymodel\n","print('writing custom configuration file')\n","\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open('pipeline_file.config', 'w') as f:\n","\n","    # Set fine_tune_checkpoint path\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","\n","    # Set tfrecord files for train and test datasets\n","    s = re.sub(\n","        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n","\n","    # Set label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set batch_size\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","\n","    # Set number of classes num_classes\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","\n","    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n","    s = re.sub(\n","        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n","\n","    # If using ssd-mobilenet-v2, reduce learning rate (because it's too high in the default config file)\n","    if chosen_model == 'ssd-mobilenet-v2':\n","      s = re.sub('learning_rate_base: .8',\n","                 'learning_rate_base: .08', s)\n","\n","      s = re.sub('warmup_learning_rate: 0.13333',\n","                 'warmup_learning_rate: .026666', s)\n","\n","    # If using efficientdet-d0, use fixed_shape_resizer instead of keep_aspect_ratio_resizer (because it isn't supported by TFLite)\n","    if chosen_model == 'efficientdet-d0':\n","      s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)\n","      s = re.sub('pad_to_max_dimension: true', '', s)\n","      s = re.sub('min_dimension', 'height', s)\n","      s = re.sub('max_dimension', 'width', s)\n","\n","    f.write(s)\n"]},{"cell_type":"code","source":["# Set the path to the custom config file and the directory to store training checkpoints in\n","pipeline_file = '/content/models/mymodel/pipeline_file.config'\n","model_dir = '/content/training/'"],"metadata":{"id":"0T1U49Pue9Ic"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["monitor training"],"metadata":{"id":"sMu0DIRNfLne"}},{"cell_type":"code","source":["%load_ext tensorboard\n","%tensorboard --logdir '/content/training/train'"],"metadata":{"id":"AFh51GlmfN1k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train\n"],"metadata":{"id":"xyr_6P6LfOhc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tQTfZChVzzpZ"},"outputs":[],"source":["# Run training!\n","!python /content/models/research/object_detection/model_main_tf2.py \\\n","    --pipeline_config_path={pipeline_file} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --sample_1_of_n_eval_examples=1"]},{"cell_type":"markdown","source":["export to tflite"],"metadata":{"id":"MUDUdXApfk_s"}},{"cell_type":"code","source":["# Make a directory to store the trained TFLite model\n","!mkdir /content/custom_model_lite\n","output_directory = '/content/custom_model_lite'\n","\n","# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n","last_model_path = '/content/training'\n","\n","!python /content/models/research/object_detection/export_tflite_graph_tf2.py \\\n","    --trained_checkpoint_dir {last_model_path} \\\n","    --output_directory {output_directory} \\\n","    --pipeline_config_path {pipeline_file}\n"],"metadata":{"id":"pPON57TBfj18"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert exported graph file into TFLite model file\n","import tensorflow as tf\n","\n","converter = tf.lite.TFLiteConverter.from_saved_model('/content/custom_model_lite/saved_model')\n","tflite_model = converter.convert()\n","\n","with open('/content/custom_model_lite/detect.tflite', 'wb') as f:\n","  f.write(tflite_model)"],"metadata":{"id":"77_9RJxkfuFT"},"execution_count":null,"outputs":[]}]}